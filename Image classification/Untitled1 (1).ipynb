{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cv2 import cv2\n",
    "from google.colab import files as FILE\n",
    "import os\n",
    "import requests \n",
    "\n",
    "train = pd.read_csv(\"training_ex3_dl2022b.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(29111):\n",
    "\n",
    "    img_data = requests.get(train['image'][i]).content\n",
    "    id = train['id'][i]\n",
    "    label =  train['label'][i]\n",
    "    name = str(id) + '_' + str(label) + '.jpg'\n",
    "    print(name)\n",
    "    with open(name, 'wb') as handler:\n",
    "      handler.write(img_data)\n",
    "\n",
    "    FILE.download(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_ex3_dl2022b.csv\")\n",
    "\n",
    "for i in range(7352):\n",
    "    img_data = requests.get(train['image'][i]).content\n",
    "    id = train['id'][i]\n",
    "    name = str(id) + '.jpg'\n",
    "    print(name)\n",
    "    with open(name, 'wb') as handler:\n",
    "      handler.write(img_data)\n",
    "\n",
    "    FILE.download(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "imgs = listdir(\"C:/Users/haimr/OneDrive/שולחן העבודה/train\")\n",
    "for item in imgs: \n",
    "    try:\n",
    "        if item.endswith(\"jpg\") :\n",
    "          fullname=str(item)\n",
    "          fullname= fullname.split(\"_\")\n",
    "          temp=fullname[-1]\n",
    "          t=temp.replace('.jpg','')\n",
    "          image = tf.keras.preprocessing.image.load_img(\"C:/Users/haimr/OneDrive/שולחן העבודה/train/\"+item,target_size=(64,64,3))\n",
    "          reimg = img_to_array(image)\n",
    "          train_Y.append(t)\n",
    "          train_X.append(reimg)  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "train_X = np.array(train_X, dtype=\"float\") / 255.0\n",
    "train_Y = np.array(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'bergamot': 0,'pomelo': 1,'yuzu': 2,'mandarin': 3,'lemon': 4,'orange': 5,'tangerine': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform = {0: 'bergamot',1: 'pomelo',2: 'yuzu',3: 'mandarin',4: 'lemon',5: 'orange',6: 'tangerine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_Y)):\n",
    "        train_Y[i]=transform[train_Y[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_Y.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "cnn = Sequential()\n",
    "\n",
    "# Params for model\n",
    "input_shape=(64, 64, 3)\n",
    "\n",
    "# Add CNN layers\n",
    "#  Stack 1:\n",
    "cnn.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Stack 2:\n",
    "cnn.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "\n",
    "# output layer:\n",
    "cnn.add(layers.Dense(64, activation='relu'))\n",
    "cnn.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 31s 84ms/step - loss: 1.4579 - accuracy: 0.4370 - val_loss: 1.3155 - val_accuracy: 0.4927\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 32s 87ms/step - loss: 1.2027 - accuracy: 0.5473 - val_loss: 1.2113 - val_accuracy: 0.5386\n",
      "Epoch 3/10\n",
      " 97/368 [======>.......................] - ETA: 20s - loss: 1.0838 - accuracy: 0.5905"
     ]
    }
   ],
   "source": [
    "cnn.fit(train_X, train_Y, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import img_to_array\n",
    "test_image = []\n",
    "test_id = []\n",
    "\n",
    "files = listdir(\"C:/Users/haimr/OneDrive/שולחן העבודה/test\")\n",
    "for item in files:\n",
    "    if item.endswith(\"jpg\") :\n",
    "      temp=str(item)\n",
    "      t=temp.replace('.jpg','')\n",
    "      test_id.append(t)\n",
    "      image2 = tf.keras.preprocessing.image.load_img(\"C:/Users/haimr/OneDrive/שולחן העבודה/test/\"+item,target_size=(64,64,3))\n",
    "      img_array2 =  img_to_array(image2)\n",
    "      test_image.append(img_array2)  \n",
    "\n",
    "\n",
    "test_X = np.array(test_image, dtype=\"float\") / 255.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "haim=pd.read_csv(\"C:/Users/haimr/OneDrive/שולחן העבודה/sample_submission_ex3_dl2022b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=cnn.predict(test_X)\n",
    "predict=(predict.argmax(axis=-1)).tolist()\n",
    "for i in range(len(predict)):\n",
    "        predict[i]=inverse_transform[predict[i]]\n",
    "\n",
    "matan=dict(zip(np.array(test_id),predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922832217</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126456633</td>\n",
       "      <td>bergamot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5006892026</td>\n",
       "      <td>bergamot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98136071</td>\n",
       "      <td>lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2579952038</td>\n",
       "      <td>bergamot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>3914749590</td>\n",
       "      <td>yuzu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>1197098425</td>\n",
       "      <td>lemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>1980553042</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>3938810201</td>\n",
       "      <td>bergamot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>3219881250</td>\n",
       "      <td>bergamot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     label\n",
       "0     1922832217    orange\n",
       "1     1126456633  bergamot\n",
       "2     5006892026  bergamot\n",
       "3       98136071     lemon\n",
       "4     2579952038  bergamot\n",
       "...          ...       ...\n",
       "7349  3914749590      yuzu\n",
       "7350  1197098425     lemon\n",
       "7351  1980553042    orange\n",
       "7352  3938810201  bergamot\n",
       "7353  3219881250  bergamot\n",
       "\n",
       "[7354 rows x 2 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ids in matan:\n",
    "    haim.loc[haim['id']==int(ids),'label']=matan[ids]\n",
    "haim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('good.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
